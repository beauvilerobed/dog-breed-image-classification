{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using AWS SageMaker\n",
    "\n",
    "In this project, we will be using AWS Sagemaker to finetune a pretrained model that can perform image classification. We will have to use Sagemaker profiling, debugger, hyperparameter tuning and other good ML engineering practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will use the dog breed classication dataset to classify between different breeds of dogs in image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch and upload the data to AWS S3\n",
    "\n",
    "# Command to download and unzip data\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!unzip dogImages.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: mys3bucket-project\n",
      "Prefix: dogImages\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::450092352571:role/service-role/AmazonSageMaker-ExecutionRole-20211220T094072\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = \"mys3bucket-project\"\n",
    "prefix = \"dogImages\"\n",
    "region =\"us-east-1\" \n",
    "role = \"arn:aws:iam::450092352571:role/service-role/AmazonSageMaker-ExecutionRole-20211220T094072\"\n",
    "\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "print(\"Prefix: {}\".format(prefix))\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] = bucket\n",
    "!aws s3 sync ./dogImages/train s3://${DEFAULT_S3_BUCKET}/dogImages/train/\n",
    "!aws s3 sync ./dogImages/test s3://${DEFAULT_S3_BUCKET}/dogImages/test/\n",
    "!aws s3 sync ./dogImages/valid s3://${DEFAULT_S3_BUCKET}/dogImages/valid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "**TODO:** This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "**Note:** You will need to use the `hpo.py` script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your HP ranges, metrics etc.\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([1, 2, 5, 7, 10]),\n",
    "    \"epochs\": IntegerParameter(2, 4)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"Testing Accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": \"Testing Accuracy\", \"Regex\": \"Testing Accuracy: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create estimators for your HPs\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# TODO: Your estimator here\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    role=role,\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "# TODO: Your HP tuner here\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your HP Tuner\n",
    "input_data = \"s3://{}/dogImages\".format(bucket)\n",
    "tuner.fit({\n",
    "'train': input_data+'/train',     \n",
    "'val': input_data+'/valid',  \n",
    "'test': input_data+'/test'     \n",
    "}) # TODO: Remember to include your data channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-12-22 16:35:46 Starting - Preparing the instances for training\n",
      "2021-12-22 16:35:46 Downloading - Downloading input data\n",
      "2021-12-22 16:35:46 Training - Training image download completed. Training in progress.\n",
      "2021-12-22 16:35:46 Uploading - Uploading generated training model\n",
      "2021-12-22 16:35:46 Completed - Training job completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"Accuracy\"',\n",
       " 'batch-size': '\"10\"',\n",
       " 'epochs': '2',\n",
       " 'lr': '0.0017043650242915514',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"pytorch-training-2021-12-22-16-25-20-037\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-450092352571/pytorch-training-2021-12-22-16-25-20-037/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Get the best estimators and the best HPs\n",
    "best_estimator = tuner.best_estimator()\n",
    "\n",
    "#Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "**Note:** You will need to use the `train_model.py` script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks\n",
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]\n",
    "\n",
    "from sagemaker.debugger import DebuggerHookConfig, ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "debugger_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "hyperparameters = {\n",
    "    \"batch_size\": 10,\n",
    "    \"gpu\": True,\n",
    "    \"epoch\": 2,\n",
    "    \"model\": \"resnet50\",\n",
    "}\n",
    "\n",
    "# TODO: Your estimator here\n",
    "estimator = PyTorch(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    entry_point=\"train_model.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    profiler_config=profiler_config,\n",
    "    debugger_hook_config=debugger_config,\n",
    "    rules=rules,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-22 17:57:43 Starting - Starting the training job...\n",
      "2021-12-22 17:58:07 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "VanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: InProgress\n",
      "LowGPUUtilization: InProgress\n",
      "ProfilerReport: InProgress\n",
      ".........\n",
      "2021-12-22 17:59:38 Starting - Preparing the instances for training.........\n",
      "2021-12-22 18:01:20 Downloading - Downloading input data....\n",
      "2021-12-22 18:11:13 Training - Training image download completed. Training in progress.LossNotDecreasing: InProgress\n",
      "VanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: IssuesFound\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-12-22 18:05:08,522 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-12-22 18:05:08,549 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-12-22 18:05:11,585 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-12-22 18:05:12,083 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"val\": \"/opt/ml/input/data/val\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 10,\n",
      "        \"epoch\": 2,\n",
      "        \"model\": \"resnet50\",\n",
      "        \"gpu\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-12-22-17-57-42-580\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-450092352571/pytorch-training-2021-12-22-17-57-42-580/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":10,\"epoch\":2,\"gpu\":true,\"model\":\"resnet50\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-450092352571/pytorch-training-2021-12-22-17-57-42-580/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":10,\"epoch\":2,\"gpu\":true,\"model\":\"resnet50\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-12-22-17-57-42-580\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-450092352571/pytorch-training-2021-12-22-17-57-42-580/source/sourcedir.tar.gz\",\"module_name\":\"train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"10\",\"--epoch\",\"2\",\"--gpu\",\"True\",\"--model\",\"resnet50\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=10\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=2\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL=resnet50\u001b[0m\n",
      "\u001b[34mSM_HP_GPU=true\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_model.py --batch_size 10 --epoch 2 --gpu True --model resnet50\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:15.087 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:15.210 algo-1:26 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34mbatch_size:10\u001b[0m\n",
      "\u001b[34mepoch:2\u001b[0m\n",
      "\u001b[34mgpu:True\u001b[0m\n",
      "\u001b[34mmodel:resnet50\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.047 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.049 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.051 algo-1:26 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.051 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mSTART TRAINING\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.678 algo-1:26 INFO hook.py:591] name:conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.678 algo-1:26 INFO hook.py:591] name:bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.679 algo-1:26 INFO hook.py:591] name:bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.679 algo-1:26 INFO hook.py:591] name:layer1.0.conv1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.680 algo-1:26 INFO hook.py:591] name:layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.680 algo-1:26 INFO hook.py:591] name:layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.681 algo-1:26 INFO hook.py:591] name:layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.681 algo-1:26 INFO hook.py:591] name:layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.681 algo-1:26 INFO hook.py:591] name:layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.682 algo-1:26 INFO hook.py:591] name:layer1.0.conv3.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.682 algo-1:26 INFO hook.py:591] name:layer1.0.bn3.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.682 algo-1:26 INFO hook.py:591] name:layer1.0.bn3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.683 algo-1:26 INFO hook.py:591] name:layer1.0.downsample.0.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.683 algo-1:26 INFO hook.py:591] name:layer1.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.684 algo-1:26 INFO hook.py:591] name:layer1.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.684 algo-1:26 INFO hook.py:591] name:layer1.1.conv1.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.684 algo-1:26 INFO hook.py:591] name:layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.685 algo-1:26 INFO hook.py:591] name:layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.685 algo-1:26 INFO hook.py:591] name:layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.686 algo-1:26 INFO hook.py:591] name:layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.686 algo-1:26 INFO hook.py:591] name:layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.686 algo-1:26 INFO hook.py:591] name:layer1.1.conv3.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.687 algo-1:26 INFO hook.py:591] name:layer1.1.bn3.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.687 algo-1:26 INFO hook.py:591] name:layer1.1.bn3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.688 algo-1:26 INFO hook.py:591] name:layer1.2.conv1.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.688 algo-1:26 INFO hook.py:591] name:layer1.2.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.688 algo-1:26 INFO hook.py:591] name:layer1.2.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.689 algo-1:26 INFO hook.py:591] name:layer1.2.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.689 algo-1:26 INFO hook.py:591] name:layer1.2.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.689 algo-1:26 INFO hook.py:591] name:layer1.2.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.690 algo-1:26 INFO hook.py:591] name:layer1.2.conv3.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.690 algo-1:26 INFO hook.py:591] name:layer1.2.bn3.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.691 algo-1:26 INFO hook.py:591] name:layer1.2.bn3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.691 algo-1:26 INFO hook.py:591] name:layer2.0.conv1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.691 algo-1:26 INFO hook.py:591] name:layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.692 algo-1:26 INFO hook.py:591] name:layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.692 algo-1:26 INFO hook.py:591] name:layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.692 algo-1:26 INFO hook.py:591] name:layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.693 algo-1:26 INFO hook.py:591] name:layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.693 algo-1:26 INFO hook.py:591] name:layer2.0.conv3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.694 algo-1:26 INFO hook.py:591] name:layer2.0.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.694 algo-1:26 INFO hook.py:591] name:layer2.0.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.694 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.695 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.695 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.696 algo-1:26 INFO hook.py:591] name:layer2.1.conv1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.696 algo-1:26 INFO hook.py:591] name:layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.696 algo-1:26 INFO hook.py:591] name:layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.697 algo-1:26 INFO hook.py:591] name:layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.697 algo-1:26 INFO hook.py:591] name:layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.697 algo-1:26 INFO hook.py:591] name:layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.698 algo-1:26 INFO hook.py:591] name:layer2.1.conv3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.698 algo-1:26 INFO hook.py:591] name:layer2.1.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.698 algo-1:26 INFO hook.py:591] name:layer2.1.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.699 algo-1:26 INFO hook.py:591] name:layer2.2.conv1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.699 algo-1:26 INFO hook.py:591] name:layer2.2.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.700 algo-1:26 INFO hook.py:591] name:layer2.2.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.700 algo-1:26 INFO hook.py:591] name:layer2.2.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.700 algo-1:26 INFO hook.py:591] name:layer2.2.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.701 algo-1:26 INFO hook.py:591] name:layer2.2.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.701 algo-1:26 INFO hook.py:591] name:layer2.2.conv3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.702 algo-1:26 INFO hook.py:591] name:layer2.2.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.702 algo-1:26 INFO hook.py:591] name:layer2.2.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.702 algo-1:26 INFO hook.py:591] name:layer2.3.conv1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.703 algo-1:26 INFO hook.py:591] name:layer2.3.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.703 algo-1:26 INFO hook.py:591] name:layer2.3.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.703 algo-1:26 INFO hook.py:591] name:layer2.3.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.704 algo-1:26 INFO hook.py:591] name:layer2.3.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.704 algo-1:26 INFO hook.py:591] name:layer2.3.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.705 algo-1:26 INFO hook.py:591] name:layer2.3.conv3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.705 algo-1:26 INFO hook.py:591] name:layer2.3.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.705 algo-1:26 INFO hook.py:591] name:layer2.3.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.706 algo-1:26 INFO hook.py:591] name:layer3.0.conv1.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.706 algo-1:26 INFO hook.py:591] name:layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.706 algo-1:26 INFO hook.py:591] name:layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.707 algo-1:26 INFO hook.py:591] name:layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.707 algo-1:26 INFO hook.py:591] name:layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.708 algo-1:26 INFO hook.py:591] name:layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.708 algo-1:26 INFO hook.py:591] name:layer3.0.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.708 algo-1:26 INFO hook.py:591] name:layer3.0.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.709 algo-1:26 INFO hook.py:591] name:layer3.0.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.709 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.0.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.709 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.1.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.710 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.1.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.710 algo-1:26 INFO hook.py:591] name:layer3.1.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.711 algo-1:26 INFO hook.py:591] name:layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.711 algo-1:26 INFO hook.py:591] name:layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.711 algo-1:26 INFO hook.py:591] name:layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.712 algo-1:26 INFO hook.py:591] name:layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.712 algo-1:26 INFO hook.py:591] name:layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.713 algo-1:26 INFO hook.py:591] name:layer3.1.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.713 algo-1:26 INFO hook.py:591] name:layer3.1.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.713 algo-1:26 INFO hook.py:591] name:layer3.1.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.714 algo-1:26 INFO hook.py:591] name:layer3.2.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.714 algo-1:26 INFO hook.py:591] name:layer3.2.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.714 algo-1:26 INFO hook.py:591] name:layer3.2.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.715 algo-1:26 INFO hook.py:591] name:layer3.2.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.715 algo-1:26 INFO hook.py:591] name:layer3.2.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.716 algo-1:26 INFO hook.py:591] name:layer3.2.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.716 algo-1:26 INFO hook.py:591] name:layer3.2.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.716 algo-1:26 INFO hook.py:591] name:layer3.2.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.717 algo-1:26 INFO hook.py:591] name:layer3.2.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.717 algo-1:26 INFO hook.py:591] name:layer3.3.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.718 algo-1:26 INFO hook.py:591] name:layer3.3.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.718 algo-1:26 INFO hook.py:591] name:layer3.3.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.718 algo-1:26 INFO hook.py:591] name:layer3.3.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.719 algo-1:26 INFO hook.py:591] name:layer3.3.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.719 algo-1:26 INFO hook.py:591] name:layer3.3.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.719 algo-1:26 INFO hook.py:591] name:layer3.3.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.720 algo-1:26 INFO hook.py:591] name:layer3.3.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.720 algo-1:26 INFO hook.py:591] name:layer3.3.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.721 algo-1:26 INFO hook.py:591] name:layer3.4.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.721 algo-1:26 INFO hook.py:591] name:layer3.4.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.721 algo-1:26 INFO hook.py:591] name:layer3.4.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.722 algo-1:26 INFO hook.py:591] name:layer3.4.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.722 algo-1:26 INFO hook.py:591] name:layer3.4.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.722 algo-1:26 INFO hook.py:591] name:layer3.4.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.723 algo-1:26 INFO hook.py:591] name:layer3.4.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.723 algo-1:26 INFO hook.py:591] name:layer3.4.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.724 algo-1:26 INFO hook.py:591] name:layer3.4.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.724 algo-1:26 INFO hook.py:591] name:layer3.5.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.724 algo-1:26 INFO hook.py:591] name:layer3.5.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.725 algo-1:26 INFO hook.py:591] name:layer3.5.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.725 algo-1:26 INFO hook.py:591] name:layer3.5.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.726 algo-1:26 INFO hook.py:591] name:layer3.5.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.726 algo-1:26 INFO hook.py:591] name:layer3.5.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.726 algo-1:26 INFO hook.py:591] name:layer3.5.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.727 algo-1:26 INFO hook.py:591] name:layer3.5.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.727 algo-1:26 INFO hook.py:591] name:layer3.5.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.727 algo-1:26 INFO hook.py:591] name:layer4.0.conv1.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.728 algo-1:26 INFO hook.py:591] name:layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.728 algo-1:26 INFO hook.py:591] name:layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.729 algo-1:26 INFO hook.py:591] name:layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.729 algo-1:26 INFO hook.py:591] name:layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.729 algo-1:26 INFO hook.py:591] name:layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.730 algo-1:26 INFO hook.py:591] name:layer4.0.conv3.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.730 algo-1:26 INFO hook.py:591] name:layer4.0.bn3.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.730 algo-1:26 INFO hook.py:591] name:layer4.0.bn3.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.731 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.0.weight count_params:2097152\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.731 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.1.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.732 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.732 algo-1:26 INFO hook.py:591] name:layer4.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.732 algo-1:26 INFO hook.py:591] name:layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.733 algo-1:26 INFO hook.py:591] name:layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.733 algo-1:26 INFO hook.py:591] name:layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.734 algo-1:26 INFO hook.py:591] name:layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.734 algo-1:26 INFO hook.py:591] name:layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.734 algo-1:26 INFO hook.py:591] name:layer4.1.conv3.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.735 algo-1:26 INFO hook.py:591] name:layer4.1.bn3.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.735 algo-1:26 INFO hook.py:591] name:layer4.1.bn3.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.735 algo-1:26 INFO hook.py:591] name:layer4.2.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.736 algo-1:26 INFO hook.py:591] name:layer4.2.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.736 algo-1:26 INFO hook.py:591] name:layer4.2.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.736 algo-1:26 INFO hook.py:591] name:layer4.2.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.737 algo-1:26 INFO hook.py:591] name:layer4.2.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.737 algo-1:26 INFO hook.py:591] name:layer4.2.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.738 algo-1:26 INFO hook.py:591] name:layer4.2.conv3.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.738 algo-1:26 INFO hook.py:591] name:layer4.2.bn3.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.738 algo-1:26 INFO hook.py:591] name:layer4.2.bn3.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.739 algo-1:26 INFO hook.py:591] name:fc.weight count_params:2048000\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.739 algo-1:26 INFO hook.py:591] name:fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.739 algo-1:26 INFO hook.py:593] Total Trainable Params: 25557032\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.740 algo-1:26 INFO hook.py:425] Monitoring the collections: losses, gradients, relu_input\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.742 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/prestepzero-*-start-1640196315211227.0_train-0-stepstart-1640196323741740.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:23.761 algo-1:26 INFO hook.py:488] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:34.285 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-stepstart-1640196323754253.8_train-0-forwardpassend-1640196334284584.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:35.227 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-forwardpassend-1640196334288364.8_train-1-stepstart-1640196335226402.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:38.326 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-1-stepstart-1640196335231741.0_train-1-forwardpassend-1640196338325727.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:38.628 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-1-forwardpassend-1640196338329239.5_train-2-stepstart-1640196338627976.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:40.976 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-2-stepstart-1640196338632012.8_train-2-forwardpassend-1640196340976285.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:42.490 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-2-forwardpassend-1640196340978119.2_train-3-stepstart-1640196342489920.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:44.518 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-3-stepstart-1640196342492995.2_train-3-forwardpassend-1640196344517969.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:44.752 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-3-forwardpassend-1640196344519752.2_train-4-stepstart-1640196344751778.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:46.799 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-4-stepstart-1640196344755550.5_train-4-forwardpassend-1640196346798793.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:47.027 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-4-forwardpassend-1640196346800469.2_train-5-stepstart-1640196347026145.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:49.046 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-5-stepstart-1640196347030162.2_train-5-forwardpassend-1640196349045937.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:49.284 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-5-forwardpassend-1640196349047706.5_train-6-stepstart-1640196349284169.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:51.345 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-6-stepstart-1640196349288025.0_train-6-forwardpassend-1640196351345477.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:51.570 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-6-forwardpassend-1640196351347470.5_train-7-stepstart-1640196351569494.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:53.601 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-7-stepstart-1640196351572981.8_train-7-forwardpassend-1640196353600861.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:53.861 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-7-forwardpassend-1640196353602589.0_train-8-stepstart-1640196353860968.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:55.895 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-8-stepstart-1640196353864401.5_train-8-forwardpassend-1640196355895213.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:56.137 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-8-forwardpassend-1640196355896799.0_train-9-stepstart-1640196356137347.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:58.206 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-9-stepstart-1640196356140370.8_train-9-forwardpassend-1640196358206122.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2021-12-22 18:05:58.493 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-9-forwardpassend-1640196358208058.0_train-10-stepstart-1640196358492921.2/python_stats.\u001b[0m\n",
      "\u001b[34mSTART VALIDATING\u001b[0m\n",
      "\u001b[34mEpoch 0: train loss 3720.800, val loss 439.535, in 194.2 sec\u001b[0m\n",
      "\u001b[34mSTART TRAINING\u001b[0m\n",
      "\u001b[34mSTART VALIDATING\u001b[0m\n",
      "\u001b[34mEpoch 1: train loss 3424.152, val loss 430.897, in 151.7 sec\u001b[0m\n",
      "\u001b[34mMedian training time per Epoch=172.9 sec\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015  4%|▍         | 4.35M/97.8M [00:00<00:02, 45.6MB/s]#015  9%|▉         | 8.78M/97.8M [00:00<00:02, 46.1MB/s]#015 15%|█▌        | 15.0M/97.8M [00:00<00:01, 54.8MB/s]#015 22%|██▏       | 21.3M/97.8M [00:00<00:01, 59.1MB/s]#015 28%|██▊       | 27.5M/97.8M [00:00<00:01, 61.5MB/s]#015 35%|███▍      | 33.8M/97.8M [00:00<00:01, 62.8MB/s]#015 41%|████      | 39.8M/97.8M [00:00<00:00, 62.8MB/s]#015 47%|████▋     | 46.1M/97.8M [00:00<00:00, 63.8MB/s]#015 54%|█████▎    | 52.4M/97.8M [00:00<00:00, 64.6MB/s]#015 60%|█████▉    | 58.6M/97.8M [00:01<00:00, 64.4MB/s]#015 66%|██████▌   | 64.7M/97.8M [00:01<00:00, 64.4MB/s]#015 73%|███████▎  | 71.0M/97.8M [00:01<00:00, 64.8MB/s]#015 79%|███████▉  | 77.2M/97.8M [00:01<00:00, 64.7MB/s]#015 85%|████████▌ | 83.4M/97.8M [00:01<00:00, 64.6MB/s]#015 92%|█████████▏| 89.5M/97.8M [00:01<00:00, 64.1MB/s]#015 98%|█████████▊| 95.8M/97.8M [00:01<00:00, 64.4MB/s]#015100%|██████████| 97.8M/97.8M [00:01<00:00, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m2021-12-22 18:11:10,387 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-12-22 18:11:47 Uploading - Uploading generated training model\n",
      "2021-12-22 18:11:47 Completed - Training job completed\n",
      "LossNotDecreasing: NoIssuesFound\n",
      "VanishingGradient: NoIssuesFound\n",
      "Overfit: NoIssuesFound\n",
      "Overtraining: NoIssuesFound\n",
      "PoorWeightInitialization: IssuesFound\n",
      "LowGPUUtilization: IssuesFound\n",
      "ProfilerReport: InProgress\n",
      "Training seconds: 622\n",
      "Billable seconds: 622\n"
     ]
    }
   ],
   "source": [
    "input_data = \"s3://{}/dogImages\".format(bucket)\n",
    "estimator.fit({\n",
    "'train': input_data+'/train',     \n",
    "'val': input_data+'/valid',      \n",
    "}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training jobname: pytorch-training-2021-12-22-17-57-42-580\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-12-22 13:22:17.056 Robeds-MacBook-Air.local:36031 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-1-450092352571/pytorch-training-2021-12-22-17-57-42-580/debug-output\n",
      "[2021-12-22 13:22:18.164 Robeds-MacBook-Air.local:36031 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2021-12-22 13:22:19.243 Robeds-MacBook-Air.local:36031 INFO trial.py:210] Loaded all steps\n",
      "['CrossEntropyLoss_output_0', 'gradient/ResNet_bn1.bias', 'gradient/ResNet_bn1.weight', 'gradient/ResNet_conv1.weight', 'gradient/ResNet_fc.bias', 'gradient/ResNet_fc.weight', 'gradient/ResNet_layer1.0.bn1.bias', 'gradient/ResNet_layer1.0.bn1.weight', 'gradient/ResNet_layer1.0.bn2.bias', 'gradient/ResNet_layer1.0.bn2.weight', 'gradient/ResNet_layer1.0.bn3.bias', 'gradient/ResNet_layer1.0.bn3.weight', 'gradient/ResNet_layer1.0.conv1.weight', 'gradient/ResNet_layer1.0.conv2.weight', 'gradient/ResNet_layer1.0.conv3.weight', 'gradient/ResNet_layer1.0.downsample.0.weight', 'gradient/ResNet_layer1.0.downsample.1.bias', 'gradient/ResNet_layer1.0.downsample.1.weight', 'gradient/ResNet_layer1.1.bn1.bias', 'gradient/ResNet_layer1.1.bn1.weight', 'gradient/ResNet_layer1.1.bn2.bias', 'gradient/ResNet_layer1.1.bn2.weight', 'gradient/ResNet_layer1.1.bn3.bias', 'gradient/ResNet_layer1.1.bn3.weight', 'gradient/ResNet_layer1.1.conv1.weight', 'gradient/ResNet_layer1.1.conv2.weight', 'gradient/ResNet_layer1.1.conv3.weight', 'gradient/ResNet_layer1.2.bn1.bias', 'gradient/ResNet_layer1.2.bn1.weight', 'gradient/ResNet_layer1.2.bn2.bias', 'gradient/ResNet_layer1.2.bn2.weight', 'gradient/ResNet_layer1.2.bn3.bias', 'gradient/ResNet_layer1.2.bn3.weight', 'gradient/ResNet_layer1.2.conv1.weight', 'gradient/ResNet_layer1.2.conv2.weight', 'gradient/ResNet_layer1.2.conv3.weight', 'gradient/ResNet_layer2.0.bn1.bias', 'gradient/ResNet_layer2.0.bn1.weight', 'gradient/ResNet_layer2.0.bn2.bias', 'gradient/ResNet_layer2.0.bn2.weight', 'gradient/ResNet_layer2.0.bn3.bias', 'gradient/ResNet_layer2.0.bn3.weight', 'gradient/ResNet_layer2.0.conv1.weight', 'gradient/ResNet_layer2.0.conv2.weight', 'gradient/ResNet_layer2.0.conv3.weight', 'gradient/ResNet_layer2.0.downsample.0.weight', 'gradient/ResNet_layer2.0.downsample.1.bias', 'gradient/ResNet_layer2.0.downsample.1.weight', 'gradient/ResNet_layer2.1.bn1.bias', 'gradient/ResNet_layer2.1.bn1.weight', 'gradient/ResNet_layer2.1.bn2.bias', 'gradient/ResNet_layer2.1.bn2.weight', 'gradient/ResNet_layer2.1.bn3.bias', 'gradient/ResNet_layer2.1.bn3.weight', 'gradient/ResNet_layer2.1.conv1.weight', 'gradient/ResNet_layer2.1.conv2.weight', 'gradient/ResNet_layer2.1.conv3.weight', 'gradient/ResNet_layer2.2.bn1.bias', 'gradient/ResNet_layer2.2.bn1.weight', 'gradient/ResNet_layer2.2.bn2.bias', 'gradient/ResNet_layer2.2.bn2.weight', 'gradient/ResNet_layer2.2.bn3.bias', 'gradient/ResNet_layer2.2.bn3.weight', 'gradient/ResNet_layer2.2.conv1.weight', 'gradient/ResNet_layer2.2.conv2.weight', 'gradient/ResNet_layer2.2.conv3.weight', 'gradient/ResNet_layer2.3.bn1.bias', 'gradient/ResNet_layer2.3.bn1.weight', 'gradient/ResNet_layer2.3.bn2.bias', 'gradient/ResNet_layer2.3.bn2.weight', 'gradient/ResNet_layer2.3.bn3.bias', 'gradient/ResNet_layer2.3.bn3.weight', 'gradient/ResNet_layer2.3.conv1.weight', 'gradient/ResNet_layer2.3.conv2.weight', 'gradient/ResNet_layer2.3.conv3.weight', 'gradient/ResNet_layer3.0.bn1.bias', 'gradient/ResNet_layer3.0.bn1.weight', 'gradient/ResNet_layer3.0.bn2.bias', 'gradient/ResNet_layer3.0.bn2.weight', 'gradient/ResNet_layer3.0.bn3.bias', 'gradient/ResNet_layer3.0.bn3.weight', 'gradient/ResNet_layer3.0.conv1.weight', 'gradient/ResNet_layer3.0.conv2.weight', 'gradient/ResNet_layer3.0.conv3.weight', 'gradient/ResNet_layer3.0.downsample.0.weight', 'gradient/ResNet_layer3.0.downsample.1.bias', 'gradient/ResNet_layer3.0.downsample.1.weight', 'gradient/ResNet_layer3.1.bn1.bias', 'gradient/ResNet_layer3.1.bn1.weight', 'gradient/ResNet_layer3.1.bn2.bias', 'gradient/ResNet_layer3.1.bn2.weight', 'gradient/ResNet_layer3.1.bn3.bias', 'gradient/ResNet_layer3.1.bn3.weight', 'gradient/ResNet_layer3.1.conv1.weight', 'gradient/ResNet_layer3.1.conv2.weight', 'gradient/ResNet_layer3.1.conv3.weight', 'gradient/ResNet_layer3.2.bn1.bias', 'gradient/ResNet_layer3.2.bn1.weight', 'gradient/ResNet_layer3.2.bn2.bias', 'gradient/ResNet_layer3.2.bn2.weight', 'gradient/ResNet_layer3.2.bn3.bias', 'gradient/ResNet_layer3.2.bn3.weight', 'gradient/ResNet_layer3.2.conv1.weight', 'gradient/ResNet_layer3.2.conv2.weight', 'gradient/ResNet_layer3.2.conv3.weight', 'gradient/ResNet_layer3.3.bn1.bias', 'gradient/ResNet_layer3.3.bn1.weight', 'gradient/ResNet_layer3.3.bn2.bias', 'gradient/ResNet_layer3.3.bn2.weight', 'gradient/ResNet_layer3.3.bn3.bias', 'gradient/ResNet_layer3.3.bn3.weight', 'gradient/ResNet_layer3.3.conv1.weight', 'gradient/ResNet_layer3.3.conv2.weight', 'gradient/ResNet_layer3.3.conv3.weight', 'gradient/ResNet_layer3.4.bn1.bias', 'gradient/ResNet_layer3.4.bn1.weight', 'gradient/ResNet_layer3.4.bn2.bias', 'gradient/ResNet_layer3.4.bn2.weight', 'gradient/ResNet_layer3.4.bn3.bias', 'gradient/ResNet_layer3.4.bn3.weight', 'gradient/ResNet_layer3.4.conv1.weight', 'gradient/ResNet_layer3.4.conv2.weight', 'gradient/ResNet_layer3.4.conv3.weight', 'gradient/ResNet_layer3.5.bn1.bias', 'gradient/ResNet_layer3.5.bn1.weight', 'gradient/ResNet_layer3.5.bn2.bias', 'gradient/ResNet_layer3.5.bn2.weight', 'gradient/ResNet_layer3.5.bn3.bias', 'gradient/ResNet_layer3.5.bn3.weight', 'gradient/ResNet_layer3.5.conv1.weight', 'gradient/ResNet_layer3.5.conv2.weight', 'gradient/ResNet_layer3.5.conv3.weight', 'gradient/ResNet_layer4.0.bn1.bias', 'gradient/ResNet_layer4.0.bn1.weight', 'gradient/ResNet_layer4.0.bn2.bias', 'gradient/ResNet_layer4.0.bn2.weight', 'gradient/ResNet_layer4.0.bn3.bias', 'gradient/ResNet_layer4.0.bn3.weight', 'gradient/ResNet_layer4.0.conv1.weight', 'gradient/ResNet_layer4.0.conv2.weight', 'gradient/ResNet_layer4.0.conv3.weight', 'gradient/ResNet_layer4.0.downsample.0.weight', 'gradient/ResNet_layer4.0.downsample.1.bias', 'gradient/ResNet_layer4.0.downsample.1.weight', 'gradient/ResNet_layer4.1.bn1.bias', 'gradient/ResNet_layer4.1.bn1.weight', 'gradient/ResNet_layer4.1.bn2.bias', 'gradient/ResNet_layer4.1.bn2.weight', 'gradient/ResNet_layer4.1.bn3.bias', 'gradient/ResNet_layer4.1.bn3.weight', 'gradient/ResNet_layer4.1.conv1.weight', 'gradient/ResNet_layer4.1.conv2.weight', 'gradient/ResNet_layer4.1.conv3.weight', 'gradient/ResNet_layer4.2.bn1.bias', 'gradient/ResNet_layer4.2.bn1.weight', 'gradient/ResNet_layer4.2.bn2.bias', 'gradient/ResNet_layer4.2.bn2.weight', 'gradient/ResNet_layer4.2.bn3.bias', 'gradient/ResNet_layer4.2.bn3.weight', 'gradient/ResNet_layer4.2.conv1.weight', 'gradient/ResNet_layer4.2.conv2.weight', 'gradient/ResNet_layer4.2.conv3.weight', 'layer1.0.relu_input_0', 'layer1.0.relu_input_1', 'layer1.0.relu_input_2', 'layer1.1.relu_input_0', 'layer1.1.relu_input_1', 'layer1.1.relu_input_2', 'layer1.2.relu_input_0', 'layer1.2.relu_input_1', 'layer1.2.relu_input_2', 'layer2.0.relu_input_0', 'layer2.0.relu_input_1', 'layer2.0.relu_input_2', 'layer2.1.relu_input_0', 'layer2.1.relu_input_1', 'layer2.1.relu_input_2', 'layer2.2.relu_input_0', 'layer2.2.relu_input_1', 'layer2.2.relu_input_2', 'layer2.3.relu_input_0', 'layer2.3.relu_input_1', 'layer2.3.relu_input_2', 'layer3.0.relu_input_0', 'layer3.0.relu_input_1', 'layer3.0.relu_input_2', 'layer3.1.relu_input_0', 'layer3.1.relu_input_1', 'layer3.1.relu_input_2', 'layer3.2.relu_input_0', 'layer3.2.relu_input_1', 'layer3.2.relu_input_2', 'layer3.3.relu_input_0', 'layer3.3.relu_input_1', 'layer3.3.relu_input_2', 'layer3.4.relu_input_0', 'layer3.4.relu_input_1', 'layer3.4.relu_input_2', 'layer3.5.relu_input_0', 'layer3.5.relu_input_1', 'layer3.5.relu_input_2', 'layer4.0.relu_input_0', 'layer4.0.relu_input_1', 'layer4.0.relu_input_2', 'layer4.1.relu_input_0', 'layer4.1.relu_input_1', 'layer4.1.relu_input_2', 'layer4.2.relu_input_0', 'layer4.2.relu_input_1', 'layer4.2.relu_input_2', 'relu_input_0']\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())\n",
    "print(trial.tensor_names())\n",
    "print(len(trial.tensor(\"CrossEntropyLoss_output_0\").steps(mode=ModeKeys.TRAIN)))\n",
    "print(\"\")\n",
    "print(len(trial.tensor(\"CrossEntropyLoss_output_0\").steps(mode=ModeKeys.EVAL)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(trial, tname, mode):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps(mode=mode)\n",
    "    vals = []\n",
    "    for s in steps:\n",
    "        vals.append(tensor.value(s, mode=mode))\n",
    "    return steps, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "\n",
    "\n",
    "def plot_tensor(trial, tensor_name):\n",
    "\n",
    "    steps_train, vals_train = get_data(trial, tensor_name, mode=ModeKeys.TRAIN)\n",
    "    print(\"loaded TRAIN data\")\n",
    "    steps_eval, vals_eval = get_data(trial, tensor_name, mode=ModeKeys.EVAL)\n",
    "    print(\"loaded EVAL data\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    host = host_subplot(111)\n",
    "\n",
    "    par = host.twiny()\n",
    "\n",
    "    host.set_xlabel(\"Steps (TRAIN)\")\n",
    "    par.set_xlabel(\"Steps (EVAL)\")\n",
    "    host.set_ylabel(tensor_name)\n",
    "\n",
    "    (p1,) = host.plot(steps_train, vals_train, label=tensor_name)\n",
    "    print(\"completed TRAIN plot\")\n",
    "    (p2,) = par.plot(steps_eval, vals_eval, label=\"val_\" + tensor_name)\n",
    "    print(\"completed EVAL plot\")\n",
    "    leg = plt.legend()\n",
    "\n",
    "    host.xaxis.get_label().set_color(p1.get_color())\n",
    "    leg.texts[0].set_color(p1.get_color())\n",
    "\n",
    "    par.xaxis.get_label().set_color(p2.get_color())\n",
    "    leg.texts[1].set_color(p2.get_color())\n",
    "\n",
    "    plt.ylabel(tensor_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TensorUnavailable",
     "evalue": "Tensor nll_loss_output_0 was not saved.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTensorUnavailable\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yc/b0_qh6xx67scyz1s3xhmn12m0000gn/T/ipykernel_36031/2100737719.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Plot a debugging output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nll_loss_output_0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/yc/b0_qh6xx67scyz1s3xhmn12m0000gn/T/ipykernel_36031/438554309.py\u001b[0m in \u001b[0;36mplot_tensor\u001b[0;34m(trial, tensor_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msteps_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded TRAIN data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msteps_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yc/b0_qh6xx67scyz1s3xhmn12m0000gn/T/ipykernel_36031/3638701402.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(trial, tname, mode)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/smdebug/trials/trial.py\u001b[0m in \u001b[0;36mtensor\u001b[0;34m(self, tname)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTensorUnavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTensorUnavailable\u001b[0m: Tensor nll_loss_output_0 was not saved."
     ]
    }
   ],
   "source": [
    "# TODO: Plot a debugging output.\n",
    "plot_tensor(trial, \"CrossEntropyLoss_output_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "\n",
    "predictor=estimator.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\") # TODO: Add your deployment configuration like instance type and number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint\n",
    "\n",
    "image = # TODO: Your code to load and preprocess image to send to endpoint for prediction\n",
    "response = predictor.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
